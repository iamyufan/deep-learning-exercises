{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-layer G and D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "\n",
    "\n",
    "# Function to select nonlinearity\n",
    "def get_nonlinearity(name):\n",
    "    if name == \"ReLU\":\n",
    "        return nn.ReLU(True)\n",
    "    elif name == \"LeakyReLU\":\n",
    "        return nn.LeakyReLU(0.2, inplace=True)\n",
    "    elif name == \"softplus\":\n",
    "        return lambda x: (torch.nn.functional.softplus(2 * x + 2) / 2) - 1\n",
    "    elif name == \"tanh\":\n",
    "        return nn.Tanh()\n",
    "    else:\n",
    "        raise ValueError(\"Invalid nonlinearity selection.\")\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        latent_dim=100,\n",
    "        num_classes=10,\n",
    "        img_channels=1,\n",
    "        num_layers=4,\n",
    "        nonlinearity=\"ReLU\",\n",
    "    ):\n",
    "        \"\"\"\n",
    "        The Generator class for DCGAN.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        latent_dim : int\n",
    "            The dimension of the latent random noise vector.\n",
    "        num_classes : int\n",
    "            The number of classes in the dataset, used for label supervision.\n",
    "        img_channels : int\n",
    "            The number of channels in the input images.\n",
    "        num_layers : int\n",
    "            The number of layers in the Generator, not including the output layer.\n",
    "        nonlinearity : str\n",
    "            The nonlinearity to use in the Generator.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.nonlinearity = nonlinearity\n",
    "        self.input_dim = latent_dim + num_classes\n",
    "\n",
    "        # The embedding layer for the class labels\n",
    "        self.label_emb = nn.Embedding(num_classes, num_classes)\n",
    "\n",
    "        # Get the main body of the Generator\n",
    "        if num_layers == 4:\n",
    "            main = self._get_4_layer()\n",
    "        elif num_layers == 8:\n",
    "            main = self._get_8_layer()\n",
    "        else:\n",
    "            raise ValueError(\"Invalid number of layers for Generator.\")\n",
    "\n",
    "        # Output layer: produces 1-channel 64x64 image in [-1, 1]\n",
    "        main.append(\n",
    "            nn.ConvTranspose2d(64, img_channels, 4, 2, 1, bias=False),\n",
    "        )\n",
    "        main.append(nn.Tanh())\n",
    "        self.main = nn.Sequential(*main)\n",
    "\n",
    "    def _get_4_layer(self):\n",
    "        return [\n",
    "            # Layer 1: (1x1) -> (4x4)\n",
    "            nn.ConvTranspose2d(self.input_dim, 512, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            get_nonlinearity(self.nonlinearity),\n",
    "            # Layer 2: (4x4) -> (8x8)\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            get_nonlinearity(self.nonlinearity),\n",
    "            # Layer 3: (8x8) -> (16x16)\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            get_nonlinearity(self.nonlinearity),\n",
    "            # Layer 4: (16x16) -> (32x32)\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            get_nonlinearity(self.nonlinearity),\n",
    "        ]\n",
    "\n",
    "    def _get_8_layer(self):\n",
    "        return [\n",
    "            # Layer 1: (1x1) -> (4x4)\n",
    "            nn.ConvTranspose2d(self.input_dim, 512, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            # Layer 2: (4x4) -> (4x4)\n",
    "            nn.ConvTranspose2d(512, 512, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            # Layer 3: (4x4) -> (8x8)\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            # Layer 4: (8x8) -> (8x8)\n",
    "            nn.ConvTranspose2d(256, 256, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            # Layer 5: (8x8) -> (16x16)\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            # Layer 6: (16x16) -> (16x16)\n",
    "            nn.ConvTranspose2d(128, 128, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            # Layer 7: (16x16) -> (32x32)\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            # Layer 8: (32x32) -> (32x32)\n",
    "            nn.ConvTranspose2d(64, 64, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "        ]\n",
    "\n",
    "    def forward(self, noise: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass of the Generator to generate fake images.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        noise : torch.Tensor (batch_size, latent_dim, 1, 1)\n",
    "            The random noise vector sampled from a normal distribution.\n",
    "        labels : torch.Tensor (batch_size)\n",
    "            The class labels for the images.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor (batch_size, img_channels, 64, 64)\n",
    "            The generated fake images.\n",
    "        \"\"\"\n",
    "        # Concatenate noise vector z and class label embedding\n",
    "        label_embedding = (\n",
    "            self.label_emb(labels).unsqueeze(2).unsqueeze(3)\n",
    "        )  # (batch_size, num_classes, 1, 1)\n",
    "        z = torch.cat(\n",
    "            [noise, label_embedding], dim=1\n",
    "        )  # (batch_size, latent_dim + num_classes, 1, 1)\n",
    "        return self.main(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 64, 64])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_noise = torch.randn(2, 100, 1, 1)\n",
    "sample_labels = torch.randint(0, 10, (2,))\n",
    "sample_images = torch.randn(2, 1, 64, 64)\n",
    "\n",
    "gen = Generator(num_layers=8, nonlinearity=\"LeakyReLU\")\n",
    "\n",
    "gen(sample_noise, sample_labels).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        latent_dim=100,\n",
    "        num_classes=10,\n",
    "        img_channels=1,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        The Generator class for DCGAN.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        latent_dim : int\n",
    "            The dimension of the latent random noise vector.\n",
    "        num_classes : int\n",
    "            The number of classes in the dataset, used for label supervision.\n",
    "        img_channels : int\n",
    "            The number of channels in the input images.\n",
    "        \"\"\"\n",
    "        super(Generator, self).__init__()\n",
    "        self.label_emb = nn.Embedding(num_classes, num_classes)\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            # Input is the latent vector z + class label, going into a transposed conv layer\n",
    "            nn.ConvTranspose2d(latent_dim + num_classes, 512, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            # Layer 2\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            # Layer 3\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            # Layer 4\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            # Output layer: produces 1-channel 64x64 image\n",
    "            nn.ConvTranspose2d(64, img_channels, 4, 2, 1, bias=False),\n",
    "            nn.Tanh(),  # Output range should be [-1, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, noise: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass of the Generator to generate fake images.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        noise : torch.Tensor (batch_size, latent_dim, 1, 1)\n",
    "            The random noise vector sampled from a normal distribution.\n",
    "        labels : torch.Tensor (batch_size)\n",
    "            The class labels for the images.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor (batch_size, img_channels, 64, 64)\n",
    "            The generated fake images.\n",
    "        \"\"\"\n",
    "        # Concatenate noise vector z and class label embedding\n",
    "        label_embedding = (\n",
    "            self.label_emb(labels).unsqueeze(2).unsqueeze(3)\n",
    "        )  # (batch_size, num_classes, 1, 1)\n",
    "        z = torch.cat(\n",
    "            [noise, label_embedding], dim=1\n",
    "        )  # (batch_size, latent_dim + num_classes, 1, 1)\n",
    "        return self.main(z)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes=10,\n",
    "        img_channels=1,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        The Discriminator class for DCGAN.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        num_classes : int\n",
    "            The number of classes in the dataset, used for label supervision.\n",
    "        img_channels : int\n",
    "            The number of channels in the input images.\n",
    "        \"\"\"\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.label_emb = nn.Embedding(num_classes, num_classes)\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            # Input is the image + class label, going into a conv layer\n",
    "            nn.Conv2d(img_channels + num_classes, 64, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # Layer 2\n",
    "            nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # Layer 3\n",
    "            nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # Layer 4\n",
    "            nn.Conv2d(256, 512, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # Output layer\n",
    "            nn.Conv2d(512, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid(),  # Output probability between 0 and 1\n",
    "        )\n",
    "\n",
    "    def forward(self, img, labels) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass of the Discriminator to classify real/fake images.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        img : torch.Tensor (batch_size, img_channels, 64, 64)\n",
    "            The input images to be classified.\n",
    "        labels : torch.Tensor (batch_size)\n",
    "            The class labels for the images.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor (batch_size, 1, 1, 1)\n",
    "            The probability of the input images being real.\n",
    "        \"\"\"\n",
    "        # Concatenate image and class label embedding\n",
    "        label_embedding = self.label_emb(labels).unsqueeze(2).unsqueeze(3)\n",
    "        label_embedding = label_embedding.expand(-1, -1, img.size(2), img.size(3))\n",
    "        img = torch.cat([img, label_embedding], dim=1)\n",
    "        return self.main(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1, 64, 64]), torch.Size([2, 1, 1, 1]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_noise = torch.randn(2, 100, 1, 1)\n",
    "sample_labels = torch.randint(0, 10, (2,))\n",
    "sample_images = torch.randn(2, 1, 64, 64)\n",
    "\n",
    "gen = Generator()\n",
    "disc = Discriminator()\n",
    "\n",
    "gen(sample_noise, sample_labels).shape, disc(sample_images, sample_labels).shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8-layer G and D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        latent_dim=100,\n",
    "        num_classes=10,\n",
    "        img_channels=1,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        The Generator class for DCGAN with 8 layers.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        latent_dim : int\n",
    "            The dimension of the latent random noise vector.\n",
    "        num_classes : int\n",
    "            The number of classes in the dataset, used for label supervision.\n",
    "        img_channels : int\n",
    "            The number of channels in the output images.\n",
    "        \"\"\"\n",
    "        super(Generator, self).__init__()\n",
    "        self.label_emb = nn.Embedding(num_classes, num_classes)\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            # Layer 1\n",
    "            nn.ConvTranspose2d(latent_dim + num_classes, 512, 4, 1, 0, bias=False),  # (1x1) -> (4x4)\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            # Layer 2\n",
    "            nn.ConvTranspose2d(512, 512, 3, 1, 1, bias=False),  # (4x4) -> (4x4)\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            # Layer 3\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),  # (4x4) -> (8x8)\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            # Layer 4\n",
    "            nn.ConvTranspose2d(256, 256, 3, 1, 1, bias=False),  # (8x8) -> (8x8)\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            # Layer 5\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),  # (8x8) -> (16x16)\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            # Layer 6\n",
    "            nn.ConvTranspose2d(128, 128, 3, 1, 1, bias=False),  # (16x16) -> (16x16)\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            # Layer 7\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),   # (16x16) -> (32x32)\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            # Layer 8\n",
    "            nn.ConvTranspose2d(64, 64, 3, 1, 1, bias=False),    # (32x32) -> (32x32)\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            # Output Layer\n",
    "            nn.ConvTranspose2d(64, img_channels, 4, 2, 1, bias=False),  # (32x32) -> (64x64)\n",
    "            nn.Tanh(),  # Output range should be [-1, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, noise: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass of the Generator to generate fake images.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        noise : torch.Tensor (batch_size, latent_dim, 1, 1)\n",
    "            The random noise vector sampled from a normal distribution.\n",
    "        labels : torch.Tensor (batch_size)\n",
    "            The class labels for the images.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor (batch_size, img_channels, 64, 64)\n",
    "            The generated fake images.\n",
    "        \"\"\"\n",
    "        # Concatenate noise vector z and class label embedding\n",
    "        label_embedding = (\n",
    "            self.label_emb(labels).unsqueeze(2).unsqueeze(3)\n",
    "        )  # (batch_size, num_classes, 1, 1)\n",
    "        z = torch.cat(\n",
    "            [noise, label_embedding], dim=1\n",
    "        )  # (batch_size, latent_dim + num_classes, 1, 1)\n",
    "        return self.main(z)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes=10,\n",
    "        img_channels=1,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        The Discriminator class for DCGAN with 8 layers.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        num_classes : int\n",
    "            The number of classes in the dataset, used for label supervision.\n",
    "        img_channels : int\n",
    "            The number of channels in the input images.\n",
    "        \"\"\"\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.label_emb = nn.Embedding(num_classes, num_classes)\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            # Layer 1\n",
    "            nn.Conv2d(img_channels + num_classes, 64, 4, 2, 1, bias=False),  # (64x64) -> (32x32)\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # Layer 2\n",
    "            nn.Conv2d(64, 64, 3, 1, 1, bias=False),  # (32x32) -> (32x32)\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # Layer 3\n",
    "            nn.Conv2d(64, 128, 4, 2, 1, bias=False),  # (32x32) -> (16x16)\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # Layer 4\n",
    "            nn.Conv2d(128, 128, 3, 1, 1, bias=False),  # (16x16) -> (16x16)\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # Layer 5\n",
    "            nn.Conv2d(128, 256, 4, 2, 1, bias=False),  # (16x16) -> (8x8)\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # Layer 6\n",
    "            nn.Conv2d(256, 256, 3, 1, 1, bias=False),  # (8x8) -> (8x8)\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # Layer 7\n",
    "            nn.Conv2d(256, 512, 4, 2, 1, bias=False),  # (8x8) -> (4x4)\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # Layer 8\n",
    "            nn.Conv2d(512, 512, 3, 1, 1, bias=False),  # (4x4) -> (4x4)\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # Output Layer\n",
    "            nn.Conv2d(512, 1, 4, 1, 0, bias=False),  # (4x4) -> (1x1)\n",
    "            nn.Sigmoid(),  # Output probability between 0 and 1\n",
    "        )\n",
    "\n",
    "    def forward(self, img, labels) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass of the Discriminator to classify real/fake images.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        img : torch.Tensor (batch_size, img_channels, 64, 64)\n",
    "            The input images to be classified.\n",
    "        labels : torch.Tensor (batch_size)\n",
    "            The class labels for the images.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor (batch_size, 1, 1, 1)\n",
    "            The probability of the input images being real.\n",
    "        \"\"\"\n",
    "        # Concatenate image and class label embedding\n",
    "        label_embedding = self.label_emb(labels).unsqueeze(2).unsqueeze(3)\n",
    "        label_embedding = label_embedding.expand(-1, -1, img.size(2), img.size(3))\n",
    "        img = torch.cat([img, label_embedding], dim=1)\n",
    "        return self.main(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1, 64, 64]), torch.Size([2, 1, 1, 1]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_noise = torch.randn(2, 100, 1, 1)\n",
    "sample_labels = torch.randint(0, 10, (2,))\n",
    "sample_images = torch.randn(2, 1, 64, 64)\n",
    "\n",
    "gen = Generator()\n",
    "disc = Discriminator()\n",
    "\n",
    "gen(sample_noise, sample_labels).shape, disc(sample_images, sample_labels).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "\n",
    "\n",
    "# Function to select nonlinearity\n",
    "def get_nonlinearity(name):\n",
    "    if name == \"ReLU\":\n",
    "        return nn.ReLU(True)\n",
    "    elif name == \"LeakyReLU\":\n",
    "        return nn.LeakyReLU(0.2, inplace=True)\n",
    "    elif name == \"softplus\":\n",
    "        return lambda x: (torch.nn.functional.softplus(2 * x + 2) / 2) - 1\n",
    "    elif name == \"tanh\":\n",
    "        return nn.Tanh()\n",
    "    else:\n",
    "        raise ValueError(\"Invalid nonlinearity selection.\")\n",
    "\n",
    "\n",
    "def get_norm_layer(norm_layer, num_features, img_shape):\n",
    "    if norm_layer == \"bn\":\n",
    "        return nn.BatchNorm2d(num_features)\n",
    "    elif norm_layer == \"ln\":\n",
    "        return nn.LayerNorm([num_features, img_shape[0], img_shape[1]])\n",
    "    elif norm_layer == \"none\":\n",
    "        return nn.Identity()\n",
    "    else:\n",
    "        raise ValueError(\"Invalid normalization layer selection.\")\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        latent_dim=100,\n",
    "        num_classes=10,\n",
    "        img_channels=1,\n",
    "        num_layers=4,\n",
    "        nonlinearity=\"ReLU\",\n",
    "    ):\n",
    "        \"\"\"\n",
    "        The Generator class for DCGAN, WGAN, and WGAN-GP.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        latent_dim : int\n",
    "            The dimension of the latent random noise vector.\n",
    "        num_classes : int\n",
    "            The number of classes in the dataset, used for label supervision.\n",
    "        img_channels : int\n",
    "            The number of channels in the input images.\n",
    "        num_layers : int\n",
    "            The number of layers in the Generator, not including the output layer.\n",
    "        nonlinearity : str\n",
    "            The nonlinearity to use in the Generator.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.nonlinearity = nonlinearity\n",
    "        self.input_dim = latent_dim + num_classes\n",
    "\n",
    "        # The embedding layer for the class labels\n",
    "        self.label_emb = nn.Embedding(num_classes, num_classes)\n",
    "\n",
    "        # Get the main body of the Generator\n",
    "        if num_layers == 4:\n",
    "            main = self._get_4_layer()\n",
    "        elif num_layers == 8:\n",
    "            main = self._get_8_layer()\n",
    "        else:\n",
    "            raise ValueError(\"Invalid number of layers for Generator.\")\n",
    "\n",
    "        # Output layer: produces 1-channel 64x64 image in [-1, 1]\n",
    "        main.add_module(\n",
    "            \"output\",\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose2d(64, img_channels, 4, 2, 1, bias=False),\n",
    "                nn.Tanh(),\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        self.main = nn.Sequential(*main)\n",
    "\n",
    "    def _get_4_layer(self) -> nn.Sequential:\n",
    "        main = nn.Sequential()\n",
    "\n",
    "        # Layer 1: (1x1) -> (4x4)\n",
    "        main.add_module(\n",
    "            \"block1\",\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose2d(self.input_dim, 512, 4, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(512),\n",
    "                get_nonlinearity(self.nonlinearity),\n",
    "            ),\n",
    "        )\n",
    "        # Layer 2: (4x4) -> (8x8)\n",
    "        main.add_module(\n",
    "            \"block2\",\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(256),\n",
    "                get_nonlinearity(self.nonlinearity),\n",
    "            ),\n",
    "        )\n",
    "        # Layer 3: (8x8) -> (16x16)\n",
    "        main.add_module(\n",
    "            \"block3\",\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(128),\n",
    "                get_nonlinearity(self.nonlinearity),\n",
    "            ),\n",
    "        )\n",
    "        # Layer 4: (16x16) -> (32x32)\n",
    "        main.add_module(\n",
    "            \"block4\",\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(64),\n",
    "                get_nonlinearity(self.nonlinearity),\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        return main\n",
    "\n",
    "    def _get_8_layer(self) -> nn.Sequential:\n",
    "        main = nn.Sequential()\n",
    "\n",
    "        # Layer 1: (1x1) -> (4x4)\n",
    "        main.add_module(\n",
    "            \"block1\",\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose2d(self.input_dim, 512, 4, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(512),\n",
    "                get_nonlinearity(self.nonlinearity),\n",
    "            ),\n",
    "        )\n",
    "        # Layer 2: (4x4) -> (4x4)\n",
    "        main.add_module(\n",
    "            \"block2\",\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose2d(512, 512, 3, 1, 1, bias=False),\n",
    "                nn.BatchNorm2d(512),\n",
    "                get_nonlinearity(self.nonlinearity),\n",
    "            ),\n",
    "        )\n",
    "        # Layer 3: (4x4) -> (8x8)\n",
    "        main.add_module(\n",
    "            \"block3\",\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(256),\n",
    "                get_nonlinearity(self.nonlinearity),\n",
    "            ),\n",
    "        )\n",
    "        # Layer 4: (8x8) -> (8x8)\n",
    "        main.add_module(\n",
    "            \"block4\",\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose2d(256, 256, 3, 1, 1, bias=False),\n",
    "                nn.BatchNorm2d(256),\n",
    "                get_nonlinearity(self.nonlinearity),\n",
    "            ),\n",
    "        )\n",
    "        # Layer 5: (8x8) -> (16x16)\n",
    "        main.add_module(\n",
    "            \"block5\",\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(128),\n",
    "                get_nonlinearity(self.nonlinearity),\n",
    "            ),\n",
    "        )\n",
    "        # Layer 6: (16x16) -> (16x16)\n",
    "        main.add_module(\n",
    "            \"block6\",\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose2d(128, 128, 3, 1, 1, bias=False),\n",
    "                nn.BatchNorm2d(128),\n",
    "                get_nonlinearity(self.nonlinearity),\n",
    "            ),\n",
    "        )\n",
    "        # Layer 7: (16x16) -> (32x32)\n",
    "        main.add_module(\n",
    "            \"block7\",\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(64),\n",
    "                get_nonlinearity(self.nonlinearity),\n",
    "            ),\n",
    "        )\n",
    "        # Layer 8: (32x32) -> (32x32)\n",
    "        main.add_module(\n",
    "            \"block8\",\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose2d(64, 64, 3, 1, 1, bias=False),\n",
    "                nn.BatchNorm2d(64),\n",
    "                get_nonlinearity(self.nonlinearity),\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        return main\n",
    "\n",
    "    def forward(self, noise: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass of the Generator to generate fake images.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        noise : torch.Tensor (batch_size, latent_dim, 1, 1)\n",
    "            The random noise vector sampled from a normal distribution.\n",
    "        labels : torch.Tensor (batch_size)\n",
    "            The class labels for the images.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor (batch_size, img_channels, 64, 64)\n",
    "            The generated fake images.\n",
    "        \"\"\"\n",
    "        # Concatenate noise vector z and class label embedding\n",
    "        label_embedding = (\n",
    "            self.label_emb(labels).unsqueeze(2).unsqueeze(3)\n",
    "        )  # (batch_size, num_classes, 1, 1)\n",
    "        z = torch.cat(\n",
    "            [noise, label_embedding], dim=1\n",
    "        )  # (batch_size, latent_dim + num_classes, 1, 1)\n",
    "        return self.main(z)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes=10,\n",
    "        img_channels=1,\n",
    "        num_layers=4,\n",
    "        nonlinearity=\"LeakyReLU\",\n",
    "    ):\n",
    "        \"\"\"\n",
    "        The Discriminator class for DCGAN.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        num_classes : int\n",
    "            The number of classes in the dataset, used for label supervision.\n",
    "        img_channels : int\n",
    "            The number of channels in the input images.\n",
    "        num_layers : int\n",
    "            The number of layers in the Discriminator, not including the output layer.\n",
    "        nonlinearity : str\n",
    "            The nonlinearity to use in the Discriminator.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.input_dim = img_channels + num_classes\n",
    "        self.nonlinearity = nonlinearity\n",
    "\n",
    "        # The embedding layer for the class labels\n",
    "        self.label_emb = nn.Embedding(num_classes, num_classes)\n",
    "\n",
    "        # Get the main body of the Discriminator\n",
    "        if num_layers == 4:\n",
    "            main = self._get_4_layer()\n",
    "        elif num_layers == 8:\n",
    "            main = self._get_8_layer()\n",
    "\n",
    "        # Output layer: produces probability of input image being real\n",
    "        main.append(\n",
    "            nn.Conv2d(512, 1, 4, 1, 0, bias=False),\n",
    "        )\n",
    "        main.append(nn.Sigmoid())\n",
    "        self.main = nn.Sequential(*main)\n",
    "\n",
    "    def _get_4_layer(self) -> nn.Sequential:\n",
    "        main = nn.Sequential()\n",
    "\n",
    "        # Layer 1: (64x64) -> (32x32)\n",
    "        main.add_module(\n",
    "            \"block1\",\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(self.input_dim, 64, 4, 2, 1, bias=False),\n",
    "                get_nonlinearity(self.nonlinearity),\n",
    "            ),\n",
    "        )\n",
    "        # Layer 2: (32x32) -> (16x16)\n",
    "        main.add_module(\n",
    "            \"block2\",\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(128),\n",
    "                get_nonlinearity(self.nonlinearity),\n",
    "            ),\n",
    "        )\n",
    "        # Layer 3: (16x16) -> (8x8)\n",
    "        main.add_module(\n",
    "            \"block3\",\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(256),\n",
    "                get_nonlinearity(self.nonlinearity),\n",
    "            ),\n",
    "        )\n",
    "        # Layer 4: (8x8) -> (4x4)\n",
    "        main.add_module(\n",
    "            \"block4\",\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(256, 512, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(512),\n",
    "                get_nonlinearity(self.nonlinearity),\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        return main\n",
    "\n",
    "    def _get_8_layer(self) -> nn.Sequential:\n",
    "        main = nn.Sequential()\n",
    "\n",
    "        # Layer 1: (64x64) -> (32x32)\n",
    "        main.add_module(\n",
    "            \"block1\",\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(self.input_dim, 64, 4, 2, 1, bias=False),\n",
    "                get_nonlinearity(self.nonlinearity),\n",
    "            ),\n",
    "        )\n",
    "        # Layer 2: (32x32) -> (32x32)\n",
    "        main.add_module(\n",
    "            \"block2\",\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(64, 64, 3, 1, 1, bias=False),\n",
    "                nn.BatchNorm2d(64),\n",
    "                get_nonlinearity(self.nonlinearity),\n",
    "            ),\n",
    "        )\n",
    "        # Layer 3: (32x32) -> (16x16)\n",
    "        main.add_module(\n",
    "            \"block3\",\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(128),\n",
    "                get_nonlinearity(self.nonlinearity),\n",
    "            ),\n",
    "        )\n",
    "        # Layer 4: (16x16) -> (16x16)\n",
    "        main.add_module(\n",
    "            \"block4\",\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(128, 128, 3, 1, 1, bias=False),\n",
    "                nn.BatchNorm2d(128),\n",
    "                get_nonlinearity(self.nonlinearity),\n",
    "            ),\n",
    "        )\n",
    "        # Layer 5: (16x16) -> (8x8)\n",
    "        main.add_module(\n",
    "            \"block5\",\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(256),\n",
    "                get_nonlinearity(self.nonlinearity),\n",
    "            ),\n",
    "        )\n",
    "        # Layer 6: (8x8) -> (8x8)\n",
    "        main.add_module(\n",
    "            \"block6\",\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(256, 256, 3, 1, 1, bias=False),\n",
    "                nn.BatchNorm2d(256),\n",
    "                get_nonlinearity(self.nonlinearity),\n",
    "            ),\n",
    "        )\n",
    "        # Layer 7: (8x8) -> (4x4)\n",
    "        main.add_module(\n",
    "            \"block7\",\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(256, 512, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(512),\n",
    "                get_nonlinearity(self.nonlinearity),\n",
    "            ),\n",
    "        )\n",
    "        # Layer 8: (4x4) -> (4x4)\n",
    "        main.add_module(\n",
    "            \"block8\",\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(512, 512, 3, 1, 1, bias=False),\n",
    "                nn.BatchNorm2d(512),\n",
    "                get_nonlinearity(self.nonlinearity),\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        return main\n",
    "\n",
    "    def forward(self, img, labels) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass of the Discriminator to classify real/fake images.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        img : torch.Tensor (batch_size, img_channels, 64, 64)\n",
    "            The input images to be classified.\n",
    "        labels : torch.Tensor (batch_size)\n",
    "            The class labels for the images.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor (batch_size, 1, 1, 1)\n",
    "            The probability of the input images being real.\n",
    "        \"\"\"\n",
    "        # Concatenate image and class label embedding\n",
    "        label_embedding = (\n",
    "            self.label_emb(labels).unsqueeze(2).unsqueeze(3)\n",
    "        )  # (batch_size, num_classes, 1, 1)\n",
    "        label_embedding = label_embedding.expand(\n",
    "            -1, -1, img.size(2), img.size(3)\n",
    "        )  # (batch_size, num_classes, 64, 64)\n",
    "        img = torch.cat(\n",
    "            [img, label_embedding], dim=1\n",
    "        )  # (batch_size, img_channels + num_classes, 64, 64)\n",
    "        return self.main(img)\n",
    "\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes=10,\n",
    "        img_channels=1,\n",
    "        num_layers=4,\n",
    "        nonlinearity=\"LeakyReLU\",\n",
    "        norm_layer=\"none\",\n",
    "    ):\n",
    "        \"\"\"\n",
    "        The Critic class for WGAN and WGAN-GP.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        num_classes : int\n",
    "            The number of classes in the dataset, used for label supervision.\n",
    "        img_channels : int\n",
    "            The number of channels in the input images.\n",
    "        num_layers : int\n",
    "            The number of layers in the Critic, not including the output layer.\n",
    "        nonlinearity : str\n",
    "            The nonlinearity to use in the Critic.\n",
    "        norm_layer : str\n",
    "            The normalization layer to use in the Critic.\n",
    "            \"bn\" for BatchNorm, \"ln\" for LayerNorm, and \"none\" for no normalization.\n",
    "            For WGAN, use \"none\". For WGAN-GP, use \"ln\".\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.input_dim = img_channels + num_classes\n",
    "        self.nonlinearity = nonlinearity\n",
    "        self.norm_layer = norm_layer\n",
    "\n",
    "        # The embedding layer for the class labels\n",
    "        self.label_emb = nn.Embedding(num_classes, num_classes)\n",
    "\n",
    "        # Get the main body of the Discriminator\n",
    "        if num_layers == 4:\n",
    "            main = self._get_4_layer()\n",
    "        elif num_layers == 8:\n",
    "            main = self._get_8_layer()\n",
    "\n",
    "        # Output layer: produces probability of input image being real\n",
    "        main.append(\n",
    "            nn.Conv2d(512, 1, 4, 1, 0, bias=False),\n",
    "        )\n",
    "        main.append(nn.Sigmoid())\n",
    "        self.main = nn.Sequential(*main)\n",
    "\n",
    "    def _get_4_layer(self) -> nn.Sequential:\n",
    "        main = nn.Sequential()\n",
    "\n",
    "        # Layer 1: (64x64) -> (32x32)\n",
    "        main.add_module(\n",
    "            \"block1\",\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(self.input_dim, 64, 4, 2, 1, bias=False),\n",
    "                get_nonlinearity(self.nonlinearity),\n",
    "            ),\n",
    "        )\n",
    "        # Layer 2: (32x32) -> (16x16)\n",
    "        main.add_module(\n",
    "            \"block2\",\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n",
    "                get_norm_layer(self.norm_layer, 128, (16, 16)),\n",
    "                get_nonlinearity(self.nonlinearity),\n",
    "            ),\n",
    "        )\n",
    "        # Layer 3: (16x16) -> (8x8)\n",
    "        main.add_module(\n",
    "            \"block3\",\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n",
    "                get_norm_layer(self.norm_layer, 256, (8, 8)),\n",
    "                get_nonlinearity(self.nonlinearity),\n",
    "            ),\n",
    "        )\n",
    "        # Layer 4: (8x8) -> (4x4)\n",
    "        main.add_module(\n",
    "            \"block4\",\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(256, 512, 4, 2, 1, bias=False),\n",
    "                get_norm_layer(self.norm_layer, 512, (4, 4)),\n",
    "                get_nonlinearity(self.nonlinearity),\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        return main\n",
    "\n",
    "    def _get_8_layer(self) -> nn.Sequential:\n",
    "        main = nn.Sequential()\n",
    "\n",
    "        # Layer 1: (64x64) -> (32x32)\n",
    "        main.add_module(\n",
    "            \"block1\",\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(self.input_dim, 64, 4, 2, 1, bias=False),\n",
    "                get_nonlinearity(self.nonlinearity),\n",
    "            ),\n",
    "        )\n",
    "        # Layer 2: (32x32) -> (32x32)\n",
    "        main.add_module(\n",
    "            \"block2\",\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(64, 64, 3, 1, 1, bias=False),\n",
    "                get_norm_layer(self.norm_layer, 64, (32, 32)),\n",
    "                get_nonlinearity(self.nonlinearity),\n",
    "            ),\n",
    "        )\n",
    "        # Layer 3: (32x32) -> (16x16)\n",
    "        main.add_module(\n",
    "            \"block3\",\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n",
    "                get_norm_layer(self.norm_layer, 128, (16, 16)),\n",
    "                get_nonlinearity(self.nonlinearity),\n",
    "            ),\n",
    "        )\n",
    "        # Layer 4: (16x16) -> (16x16)\n",
    "        main.add_module(\n",
    "            \"block4\",\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(128, 128, 3, 1, 1, bias=False),\n",
    "                get_norm_layer(self.norm_layer, 128, (16, 16)),\n",
    "                get_nonlinearity(self.nonlinearity),\n",
    "            ),\n",
    "        )\n",
    "        # Layer 5: (16x16) -> (8x8)\n",
    "        main.add_module(\n",
    "            \"block5\",\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n",
    "                get_norm_layer(self.norm_layer, 256, (8, 8)),\n",
    "                get_nonlinearity(self.nonlinearity),\n",
    "            ),\n",
    "        )\n",
    "        # Layer 6: (8x8) -> (8x8)\n",
    "        main.add_module(\n",
    "            \"block6\",\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(256, 256, 3, 1, 1, bias=False),\n",
    "                get_norm_layer(self.norm_layer, 256, (8, 8)),\n",
    "                get_nonlinearity(self.nonlinearity),\n",
    "            ),\n",
    "        )\n",
    "        # Layer 7: (8x8) -> (4x4)\n",
    "        main.add_module(\n",
    "            \"block7\",\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(256, 512, 4, 2, 1, bias=False),\n",
    "                get_norm_layer(self.norm_layer, 512, (4, 4)),\n",
    "                get_nonlinearity(self.nonlinearity),\n",
    "            ),\n",
    "        )\n",
    "        # Layer 8: (4x4) -> (4x4)\n",
    "        main.add_module(\n",
    "            \"block8\",\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(512, 512, 3, 1, 1, bias=False),\n",
    "                get_norm_layer(self.norm_layer, 512, (4, 4)),\n",
    "                get_nonlinearity(self.nonlinearity),\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        return main\n",
    "\n",
    "    def forward(self, img, labels) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass of the Discriminator to classify real/fake images.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        img : torch.Tensor (batch_size, img_channels, 64, 64)\n",
    "            The input images to be classified.\n",
    "        labels : torch.Tensor (batch_size)\n",
    "            The class labels for the images.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor (batch_size, 1, 1, 1)\n",
    "            The probability of the input images being real.\n",
    "        \"\"\"\n",
    "        # Concatenate image and class label embedding\n",
    "        label_embedding = (\n",
    "            self.label_emb(labels).unsqueeze(2).unsqueeze(3)\n",
    "        )  # (batch_size, num_classes, 1, 1)\n",
    "        label_embedding = label_embedding.expand(\n",
    "            -1, -1, img.size(2), img.size(3)\n",
    "        )  # (batch_size, num_classes, 64, 64)\n",
    "        img = torch.cat(\n",
    "            [img, label_embedding], dim=1\n",
    "        )  # (batch_size, img_channels + num_classes, 64, 64)\n",
    "        return self.main(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1, 64, 64]),\n",
       " torch.Size([2, 1, 1, 1]),\n",
       " torch.Size([2, 1, 1, 1]))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_noise = torch.randn(2, 100, 1, 1)\n",
    "sample_labels = torch.randint(0, 10, (2,))\n",
    "sample_images = torch.randn(2, 1, 64, 64)\n",
    "\n",
    "gen = Generator(num_layers=4, nonlinearity=\"LeakyReLU\")\n",
    "disc = Discriminator(num_layers=4, nonlinearity=\"LeakyReLU\")\n",
    "crit = Critic(num_layers=8, nonlinearity=\"LeakyReLU\", norm_layer=\"bn\")\n",
    "\n",
    "# Should output: (2, 1, 64, 64), (2, 1, 1, 1), (2, 1, 1, 1)\n",
    "gen(sample_noise, sample_labels).shape, disc(sample_images, sample_labels).shape, crit(sample_images, sample_labels).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critic(\n",
      "  (label_emb): Embedding(10, 10)\n",
      "  (main): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(11, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): Identity()\n",
      "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): Identity()\n",
      "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): Identity()\n",
      "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (4): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (5): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(crit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "\n",
    "\n",
    "# Function to select nonlinearity\n",
    "def get_nonlinearity(name):\n",
    "    if name == \"ReLU\":\n",
    "        return nn.ReLU(True)\n",
    "    elif name == \"LeakyReLU\":\n",
    "        return nn.LeakyReLU(0.2, inplace=True)\n",
    "    elif name == \"softplus\":\n",
    "        return lambda x: (torch.nn.functional.softplus(2 * x + 2) / 2) - 1\n",
    "    elif name == \"tanh\":\n",
    "        return nn.Tanh()\n",
    "    else:\n",
    "        raise ValueError(\"Invalid nonlinearity selection.\")\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        latent_dim=100,\n",
    "        num_classes=10,\n",
    "        img_channels=1,\n",
    "        nonlinearity=\"ReLU\",\n",
    "    ):\n",
    "        \"\"\"\n",
    "        The Generator class for DCGAN.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        latent_dim : int\n",
    "            The dimension of the latent random noise vector.\n",
    "        num_classes : int\n",
    "            The number of classes in the dataset, used for label supervision.\n",
    "        img_channels : int\n",
    "            The number of channels in the input images.\n",
    "        nonlinearity : str\n",
    "            The nonlinearity to use in the Generator.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.label_emb = nn.Embedding(num_classes, num_classes)\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            # Input is the latent vector z + class label, going into a transposed conv layer\n",
    "            nn.ConvTranspose2d(latent_dim + num_classes, 512, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            get_nonlinearity(nonlinearity),\n",
    "            # Layer 2\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            get_nonlinearity(nonlinearity),\n",
    "            # Layer 3\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            get_nonlinearity(nonlinearity),\n",
    "            # Layer 4\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            get_nonlinearity(nonlinearity),\n",
    "            # Output layer: produces 1-channel 64x64 image\n",
    "            nn.ConvTranspose2d(64, img_channels, 4, 2, 1, bias=False),\n",
    "            nn.Tanh(),  # Output range should be [-1, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, noise: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass of the Generator to generate fake images.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        noise : torch.Tensor (batch_size, latent_dim, 1, 1)\n",
    "            The random noise vector sampled from a normal distribution.\n",
    "        labels : torch.Tensor (batch_size)\n",
    "            The class labels for the images.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor (batch_size, img_channels, 64, 64)\n",
    "            The generated fake images.\n",
    "        \"\"\"\n",
    "        # Concatenate noise vector z and class label embedding\n",
    "        label_embedding = (\n",
    "            self.label_emb(labels).unsqueeze(2).unsqueeze(3)\n",
    "        )  # (batch_size, num_classes, 1, 1)\n",
    "        z = torch.cat(\n",
    "            [noise, label_embedding], dim=1\n",
    "        )  # (batch_size, latent_dim + num_classes, 1, 1)\n",
    "        return self.main(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "generator = Generator()\n",
    "\n",
    "sample_batch_image = torch.randn(1, 100, 1, 1)\n",
    "sample_batch_label = torch.randint(0, 10, (1,))\n",
    "output = generator(sample_batch_image, sample_batch_label)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        latent_dim=100,\n",
    "        num_classes=10,\n",
    "        img_channels=1,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        The Generator class for DCGAN with 8 layers.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        latent_dim : int\n",
    "            The dimension of the latent random noise vector.\n",
    "        num_classes : int\n",
    "            The number of classes in the dataset, used for label supervision.\n",
    "        img_channels : int\n",
    "            The number of channels in the output images.\n",
    "        \"\"\"\n",
    "        super(Generator, self).__init__()\n",
    "        self.label_emb = nn.Embedding(num_classes, num_classes)\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            # Layer 1\n",
    "            nn.ConvTranspose2d(latent_dim + num_classes, 512, 4, 1, 0, bias=False),  # (1x1) -> (4x4)\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            # Layer 2\n",
    "            nn.ConvTranspose2d(512, 512, 3, 1, 1, bias=False),  # (4x4) -> (4x4)\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            # Layer 3\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),  # (4x4) -> (8x8)\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            # Layer 4\n",
    "            nn.ConvTranspose2d(256, 256, 3, 1, 1, bias=False),  # (8x8) -> (8x8)\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            # Layer 5\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),  # (8x8) -> (16x16)\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            # Layer 6\n",
    "            nn.ConvTranspose2d(128, 128, 3, 1, 1, bias=False),  # (16x16) -> (16x16)\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            # Layer 7\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),   # (16x16) -> (32x32)\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            # Layer 8\n",
    "            nn.ConvTranspose2d(64, 64, 3, 1, 1, bias=False),    # (32x32) -> (32x32)\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            # Output Layer\n",
    "            nn.ConvTranspose2d(64, img_channels, 4, 2, 1, bias=False),  # (32x32) -> (64x64)\n",
    "            nn.Tanh(),  # Output range should be [-1, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, noise: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass of the Generator to generate fake images.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        noise : torch.Tensor (batch_size, latent_dim, 1, 1)\n",
    "            The random noise vector sampled from a normal distribution.\n",
    "        labels : torch.Tensor (batch_size)\n",
    "            The class labels for the images.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor (batch_size, img_channels, 64, 64)\n",
    "            The generated fake images.\n",
    "        \"\"\"\n",
    "        # Concatenate noise vector z and class label embedding\n",
    "        label_embedding = (\n",
    "            self.label_emb(labels).unsqueeze(2).unsqueeze(3)\n",
    "        )  # (batch_size, num_classes, 1, 1)\n",
    "        z = torch.cat(\n",
    "            [noise, label_embedding], dim=1\n",
    "        )  # (batch_size, latent_dim + num_classes, 1, 1)\n",
    "        return self.main(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "generator = Generator()\n",
    "\n",
    "sample_batch_image = torch.randn(1, 100, 1, 1)\n",
    "sample_batch_label = torch.randint(0, 10, (1,))\n",
    "output = generator(sample_batch_image, sample_batch_label)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (5): ReLU(inplace=True)\n",
      "  (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (8): ReLU(inplace=True)\n",
      "  (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (11): ReLU(inplace=True)\n",
      "  (12): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (13): Tanh()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "num_layers = 4\n",
    "base_filter_count = 64\n",
    "generator = build_generator(num_layers, base_filter_count)\n",
    "print(generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): ConvTranspose2d(100, 8192, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(8192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): ConvTranspose2d(8192, 4096, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (4): BatchNorm2d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (5): ReLU(inplace=True)\n",
      "  (6): ConvTranspose2d(4096, 2048, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (7): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (8): ReLU(inplace=True)\n",
      "  (9): ConvTranspose2d(2048, 1024, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (10): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (11): ReLU(inplace=True)\n",
      "  (12): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (13): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (14): ReLU(inplace=True)\n",
      "  (15): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (16): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (17): ReLU(inplace=True)\n",
      "  (18): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (19): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (20): ReLU(inplace=True)\n",
      "  (21): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (22): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (23): ReLU(inplace=True)\n",
      "  (24): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (25): Tanh()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "num_layers = 8\n",
    "base_filter_count = 64\n",
    "generator = build_generator(num_layers, base_filter_count)\n",
    "print(generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "sample_batch = torch.randn(1, 100, 1, 1)\n",
    "output = generator(sample_batch)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        latent_dim=100,\n",
    "        num_classes=10,\n",
    "        img_channels=1,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        The Generator class for DCGAN.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        latent_dim : int\n",
    "            The dimension of the latent random noise vector.\n",
    "        num_classes : int\n",
    "            The number of classes in the dataset, used for label supervision.\n",
    "        img_channels : int\n",
    "            The number of channels in the input images.\n",
    "        \"\"\"\n",
    "        super(Generator, self).__init__()\n",
    "        self.label_emb = nn.Embedding(num_classes, num_classes)\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            # Input is the latent vector z + class label, going into a transposed conv layer\n",
    "            nn.ConvTranspose2d(latent_dim + num_classes, 512, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            # Layer 2\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            # Layer 3\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            # Layer 4\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            # Output layer: produces 1-channel 64x64 image\n",
    "            nn.ConvTranspose2d(64, img_channels, 4, 2, 1, bias=False),\n",
    "            nn.Tanh(),  # Output range should be [-1, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, noise: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass of the Generator to generate fake images.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        noise : torch.Tensor (batch_size, latent_dim, 1, 1)\n",
    "            The random noise vector sampled from a normal distribution.\n",
    "        labels : torch.Tensor (batch_size)\n",
    "            The class labels for the images.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor (batch_size, img_channels, 64, 64)\n",
    "            The generated fake images.\n",
    "        \"\"\"\n",
    "        # Concatenate noise vector z and class label embedding\n",
    "        label_embedding = (\n",
    "            self.label_emb(labels).unsqueeze(2).unsqueeze(3)\n",
    "        )  # (batch_size, num_classes, 1, 1)\n",
    "        z = torch.cat(\n",
    "            [noise, label_embedding], dim=1\n",
    "        )  # (batch_size, latent_dim + num_classes, 1, 1)\n",
    "        return self.main(z)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes=10,\n",
    "        img_channels=1,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        The Discriminator class for DCGAN.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        num_classes : int\n",
    "            The number of classes in the dataset, used for label supervision.\n",
    "        img_channels : int\n",
    "            The number of channels in the input images.\n",
    "        \"\"\"\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.label_emb = nn.Embedding(num_classes, num_classes)\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            # Input is the image + class label, going into a conv layer\n",
    "            nn.Conv2d(img_channels + num_classes, 64, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # Layer 2\n",
    "            nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # Layer 3\n",
    "            nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # Layer 4\n",
    "            nn.Conv2d(256, 512, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # Output layer\n",
    "            nn.Conv2d(512, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid(),  # Output probability between 0 and 1\n",
    "        )\n",
    "\n",
    "    def forward(self, img, labels) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass of the Discriminator to classify real/fake images.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        img : torch.Tensor (batch_size, img_channels, 64, 64)\n",
    "            The input images to be classified.\n",
    "        labels : torch.Tensor (batch_size)\n",
    "            The class labels for the images.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor (batch_size, 1, 1, 1)\n",
    "            The probability of the input images being real.\n",
    "        \"\"\"\n",
    "        # Concatenate image and class label embedding\n",
    "        label_embedding = self.label_emb(labels).unsqueeze(2).unsqueeze(3)\n",
    "        label_embedding = label_embedding.expand(-1, -1, img.size(2), img.size(3))\n",
    "        img = torch.cat([img, label_embedding], dim=1)\n",
    "        return self.main(img)\n",
    "\n",
    "\n",
    "class DCGAN:\n",
    "    def __init__(\n",
    "        self,\n",
    "        latent_dim=100,\n",
    "        num_classes=10,\n",
    "        img_channels=1,\n",
    "        learning_rate=0.0002,\n",
    "        beta1=0.2,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        The DCGAN class that combines the Generator and Discriminator.\n",
    "        Follows the PyTorch Lightning Module structure that wraps the training loop.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        latent_dim : int\n",
    "            The dimension of the latent random noise vector.\n",
    "        num_classes : int\n",
    "            The number of classes in the dataset, used for label supervision.\n",
    "        img_channels : int\n",
    "            The number of channels in the input images.\n",
    "        learning_rate : float\n",
    "            The learning rate for the optimizer.\n",
    "        beta1 : float\n",
    "            The beta1 parameter for the Adam optimizer.\n",
    "        \"\"\"\n",
    "        super(DCGAN, self).__init__()\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        # Configuration for the model\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.img_channels = img_channels\n",
    "\n",
    "        # Generator and Discriminator\n",
    "        self.netG = Generator(self.latent_dim, self.num_classes, self.img_channels).to(\n",
    "            self.device\n",
    "        )\n",
    "        self.netD = Discriminator(self.num_classes, self.img_channels).to(self.device)\n",
    "\n",
    "        # Training configurations\n",
    "        self.learning_rate = learning_rate\n",
    "        self.beta1 = beta1\n",
    "\n",
    "    @property\n",
    "    def criterion(self):\n",
    "        if not hasattr(self, \"_criterion\"):\n",
    "            self._criterion = nn.BCELoss()\n",
    "        return self._criterion\n",
    "\n",
    "    @property\n",
    "    def optimizerG(self):\n",
    "        if not hasattr(self, \"_optimizerG\"):\n",
    "            self._optimizerG = optim.Adam(\n",
    "                self.netG.parameters(), lr=self.learning_rate, betas=(self.beta1, 0.999)\n",
    "            )\n",
    "        return self._optimizerG\n",
    "\n",
    "    @property\n",
    "    def optimizerD(self):\n",
    "        if not hasattr(self, \"_optimizerD\"):\n",
    "            self._optimizerD = optim.Adam(\n",
    "                self.netD.parameters(), lr=self.learning_rate, betas=(self.beta1, 0.999)\n",
    "            )\n",
    "        return self._optimizerD\n",
    "\n",
    "    def forward(self, noise: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass of the Generator to generate fake images.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        noise : torch.Tensor (batch_size, latent_dim, 1, 1)\n",
    "            The random noise vector sampled from a normal distribution.\n",
    "        labels : torch.Tensor (batch_size)\n",
    "            The class labels for the images.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor (batch_size, img_channels, 64, 64)\n",
    "            The generated fake images.\n",
    "        \"\"\"\n",
    "        return self.netG(noise, labels)\n",
    "\n",
    "    def training_step(\n",
    "        self,\n",
    "        batch: Tuple[torch.Tensor],\n",
    "        batch_idx: int,\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Run a single training step on a batch of data and\n",
    "        return the losses of the Generator and Discriminator.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch : Tuple[torch.Tensor]\n",
    "            A tuple containing\n",
    "            - input images (batch_size, img_channels, 64, 64) and\n",
    "            - labels (batch_size).\n",
    "        batch_idx : int\n",
    "            The index of the current batch.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        errG : torch.Tensor\n",
    "            The loss of the Generator.\n",
    "        errD : torch.Tensor\n",
    "            The loss of the Discriminator.\n",
    "        \"\"\"\n",
    "        real_images, real_labels = batch\n",
    "        real_images = real_images.to(self.device)\n",
    "        real_labels = real_labels.to(self.device)\n",
    "        batch_size = real_images.size(0)\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "        self.netD.zero_grad()\n",
    "\n",
    "        # Train on real images\n",
    "        label = torch.full((batch_size,), 1.0, dtype=torch.float).to(\n",
    "            self.device\n",
    "        )  # All ones label for real images\n",
    "        output = self.netD(real_images, real_labels).view(-1)\n",
    "        errD_real = self.criterion(output, label)\n",
    "        errD_real.backward()\n",
    "\n",
    "        # Train on fake images\n",
    "        noise = torch.randn(batch_size, self.latent_dim, 1, 1).to(self.device)\n",
    "        fake_labels = torch.randint(0, self.num_classes, (batch_size,)).to(self.device)\n",
    "        fake_images = self.netG(noise, fake_labels)\n",
    "        label.fill_(0.0)  # All zeros label for fake images\n",
    "        output = self.netD(fake_images.detach(), fake_labels).view(-1)\n",
    "        errD_fake = self.criterion(output, label)\n",
    "        errD_fake.backward()\n",
    "\n",
    "        errD = errD_real + errD_fake\n",
    "        self.optimizerD.step()\n",
    "\n",
    "        ## Train Generator ##\n",
    "        self.netG.zero_grad()\n",
    "        label.fill_(1.0)  # The generator wants to trick the discriminator\n",
    "\n",
    "        output = self.netD(fake_images, fake_labels).view(-1)\n",
    "        errG = self.criterion(output, label)\n",
    "        errG.backward()\n",
    "        self.optimizerG.step()\n",
    "\n",
    "        return errG, errD\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return [self.optimizerG, self.optimizerD], []\n",
    "\n",
    "    def generate_images_by_label(self, num_images: int, label: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Generate fake images in the format of torchvision grid\n",
    "        given a class label.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        num_images : int\n",
    "            The number of images to generate.\n",
    "        label: int\n",
    "            The class label for the images.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        grid : torch.Tensor (3, H, W)\n",
    "            The grid of fake images.\n",
    "        \"\"\"\n",
    "        noise = torch.randn(num_images, self.latent_dim, 1, 1).to(self.device)\n",
    "        labels = torch.full((num_images,), label, dtype=torch.long).to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            fake_images = self.forward(noise, labels).detach().cpu()\n",
    "\n",
    "        grid = torchvision.utils.make_grid(fake_images, nrow=10, normalize=True)\n",
    "        return grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
